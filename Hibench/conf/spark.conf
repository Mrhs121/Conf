# Spark home
hibench.spark.home     /root/app/spark-2.4.5-bin-hadoop2.7 

# Spark master
#spark://hp-01:7077
#   YARN mode: yarn-client
hibench.spark.master    spark://hp-01:7077
#hibench.spark.master    yarn-client

# executor number and cores when running on Yarn
hibench.yarn.executor.num     2
hibench.yarn.executor.cores   4

# executor and driver memory in standalone & YARN mode
#spark.executor.memory  512M
#spark.driver.memory    512M

# set spark parallelism property according to hibench's parallelism value
#spark.default.parallelism     ${hibench.default.map.parallelism}

# set spark sql's default shuffle partitions according to hibench's parallelism value
spark.sql.shuffle.partitions  ${hibench.default.shuffle.parallelism}


    spark.driver.cores  2
    spark.executor.cores    4
    spark.driver.memory 2048M
    spark.executor.memory    2048M
    spark.driver.maxResultSize 2048M
    spark.reducer.maxSizeInFlight 16
    spark.shuffle.compress true
    spark.shuffle.file.buffer 32
    spark.shuffle.spill.compress true
    spark.broadcast.compress true
    spark.io.compression.codec snappy
    spark.rdd.compress true
    spark.serializer org.apache.spark.serializer.KryoSerializer 
    spark.broadcast.blockSize 4096
    spark.speculation.multiplier 1.5
    spark.task.cpus 1 
    spark.rpc.message.maxSize 128
    spark.storage.memoryMapThreshold 2097152
    spark.files.useFetchCache true
    spark.default.parallelism 2





#======================================================
# Spark Streaming
#======================================================
# Spark streaming Batchnterval in millisecond (default 100)
hibench.streambench.spark.batchInterval          100

# Number of nodes that will receive kafka input (default: 4)
hibench.streambench.spark.receiverNumber        4

# Indicate RDD storage level. (default: 2)
# 0 = StorageLevel.MEMORY_ONLY
# 1 = StorageLevel.MEMORY_AND_DISK_SER
# other = StorageLevel.MEMORY_AND_DISK_SER_2
hibench.streambench.spark.storageLevel 2

# indicate whether to test the write ahead log new feature (default: false)
hibench.streambench.spark.enableWAL false

# if testWAL is true, this path to store stream context in hdfs shall be specified. If false, it can be empty (default: /var/tmp)
hibench.streambench.spark.checkpointPath /var/tmp

# whether to use direct approach or not (dafault: true)
hibench.streambench.spark.useDirectMode true
